# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md
image: "r8.im/terrafying/dance-diffusion"

build:
  # set to true if your model requires a GPU
  gpu: true

  # a list of ubuntu apt packages to install
  system_packages:
    - "curl"
    - "ffmpeg"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.8"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "numpy==1.21.6"
    - "torchvision==0.10.0"
    - "torch==1.9.0"
    - "torchaudio==0.9.0"

  # commands run after the environment is setup
  run:
    - pip install --upgrade pip
    - pip install einops pandas prefigure pytorch_lightning scipy torch tqdm wandb
    - mkdir /models
    - git clone https://github.com/harmonai-org/sample-generator
    - git clone --recursive https://github.com/crowsonkb/v-diffusion-pytorch
    - pip install /sample-generator
    - pip install /v-diffusion-pytorch
    - pip install matplotlib soundfile
    - wget -O /models/gwf-440k.ckpt https://model-server.zqevans2.workers.dev/gwf-440k.ckpt > /dev/null 2>&1 
    - wget -O /models/jmann-large-580k.ckpt https://model-server.zqevans2.workers.dev/jmann-large-580k.ckpt > /dev/null 2>&1
predict: "predict.py:Predictor"
